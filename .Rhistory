pca.train5 <- princomp(gruppo5_train, cor=T)
summary(pca.train5)
biplot(pca.train5)
abline(h=0, v=0)
pca.train5$loadings
pca.train5$scores
conflict_manag <- pca.train5$scores[,1]
# PCA Gruppo 6 training
pca.train6 <- princomp(gruppo6_train, cor=T)
summary(pca.train6)
biplot(pca.train6)
abline(h=0, v=0)
pca.train6$loadings
pca.train6$scores
shared_goals <- pca.train6$scores[,1]
train.df <- data.frame(friend_int,
knowledge,
indifference,
aggression,
conflict_manag,
shared_goals,
train[,55])
### PCA TEST (addestrate su training)
pca.test1 <- predict(pca.train1, newdata = gruppo1_test)
pca.test2 <- predict(pca.train2, newdata = gruppo2_test)
pca.test3 <- predict(pca.train3, newdata = gruppo3_test)
pca.test4 <- predict(pca.train4, newdata = gruppo4_test)
pca.test5 <- predict(pca.train5, newdata = gruppo5_test)
pca.test6 <- predict(pca.train6, newdata = gruppo6_test)
friend_int_test <- pca.test1[,1]
knowledge_test <- pca.test2[,1]
indifference_test <- pca.test3[,1]
aggression_test <- pca.test4[,1]
conflict_manag_test <- pca.test5[,1]
shared_goals_test <- pca.test6[,1]
test.df <- data.frame(friend_int_test,
knowledge_test,
indifference_test,
aggression_test,
conflict_manag_test,
shared_goals_test,
test[,55])
colnames(train.df)[7] <- "Divorce"
colnames(test.df)[7] <- "Divorce"
# abbastanza bilanciati sia training sia test:
round(prop.table(table(train.df$Divorce)), 2)
round(prop.table(table(test.df$Divorce)), 2)
### ANALISI CORRELAZIONE E DISTRIBUZIONI MARGINALI
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(cor(train.df), method="color", col=col(200),
type="upper", order="hclust",
addCoef.col = "black", # Add coefficient of correlation
tl.col="black", tl.srt=45, #Text label color and rotation
# hide correlation coefficient on the principal diagonal
diag=FALSE
)
library(glmnet)
x <- model.matrix(Divorce~., data=train.df)
y <- train.df$Divorce
fit.ridge <- glmnet(x,y,alpha=0)
plot(fit.ridge,xvar="lambda",label=TRUE)
predictions <- predict(ridge_model, newx = x)
cv_fit <- cv.glmnet(x, y, alpha = 0)
lambda_optimal <- cv_fit$lambda.min
fit.ridge_optimal <- glmnet(x, y, alpha = 0, lambda = lambda_optimal)
coefficients <- coef(fit.ridge_optimal)
# Estrai il sottoinsieme di coefficienti stimati corrispondenti alle variabili predittive
ridge_coefficients <- coefficients[-1]
# Crea una matrice di design per la regressione logistica utilizzando le stesse variabili predittive
x_logistic <- model.matrix(Divorce ~ ., data = test.df)
# Addestra il modello di regressione logistica utilizzando i coefficienti stimati dalla regressione ridge
logistic_model <- glm(Divorce ~ ., data = train.df, family = binomial)
summary(logistic_model)
library(randomForest)
rf_model <- randomForest(Divorce ~ ., data = train.df)
# Visualizza un sommario del modello
print(rf_model)
# Valuta le prestazioni del modello utilizzando il set di test
predictions <- predict(rf_model, newdata = test_data)
# Valuta le prestazioni del modello utilizzando il set di test
predictions <- predict(rf_model, newdata = test.df)
View(test.df)
View(test.df)
# Valuta le prestazioni del modello utilizzando il set di test
predictions <- predict(rf_model, newdata = test.df)
View(train.df)
names(test.df)[1] <- "friend_int"
names(test.df)[1] <- "friend_int"
names(test.df)[1] <- "friend_int"train.df <- data.frame(friend_int,
names(test.df)[2] <- "knowledge"
names(test.df)[3] <- "indifference"
names(test.df)[4] <- "aggression"
names(test.df)[5] <- "conflict_manag"
names(test.df)[6] <- "shared_goals"
# Valuta le prestazioni del modello utilizzando il set di test
predictions <- predict(rf_model, newdata = test.df)
predictions
# Calcola l'accuratezza del modello
accuracy <- mean(predictions == test_data$Divorce)
# Calcola l'accuratezza del modello
accuracy <- mean(predictions == test.df$Divorce)
print(paste("Accuracy:", accuracy))
###
library(readr)
library(corrplot)
library(ggplot2)
library(DT)
library(caret)
library(nnet)
library(glmnet)
library(MASS)
pca.train <- princomp(train[,-55], cor=T)
summary(pca.train) # 4 comp
biplot(pca.train)
abline(h=0, v=0)
pca.train$loadings[, 1:4]
pca.train$scores[, 1:4]
train.df.4 <- data.frame(pca.train$scores[, 1:4], train[,"Divorce"])
test.df.4 <- data.frame(predict(pca.train, newdata = test)[, 1:4], test[,"Divorce"])
colnames(train.df.4) <- c("Harmony_Understanding", "Intimacy_Love", "Similarity_Cohesion",
"Conflict_Level", "Divorce")
colnames(test.df.4) <- c("Harmony_Understanding", "Intimacy_Love", "Similarity_Cohesion",
"Conflict_Level", "Divorce")
library(randomForest)
rf_model <- randomForest(Divorce ~ ., data = train.df.4)
# Visualizza un sommario del modello
print(rf_model)
# Valuta le prestazioni del modello utilizzando il set di test
predictions <- predict(rf_model, newdata = test.df.4)
predictions
# Calcola l'accuratezza del modello
accuracy <- mean(predictions == test.df$Divorce)
print(paste("Accuracy:", accuracy))
# Calcola l'accuratezza del modello
accuracy <- mean(predictions == test.df.4$Divorce)
print(paste("Accuracy:", accuracy))
rf_model <- randomForest(Divorce ~ ., data = train.df.4)
# Visualizza un sommario del modello
print(rf_model)
# Valuta le prestazioni del modello utilizzando il set di test
predictions <- predict(rf_model, newdata = test.df.4)
predictions
# Calcola l'accuratezza del modello
accuracy <- mean(predictions == test.df.4$Divorce)
print(paste("Accuracy:", accuracy))
rf_model <- randomForest(Divorce ~ ., data = train.df)
# Valuta le prestazioni del modello utilizzando il set di test
predictions <- predict(rf_model, newdata = test.df)
predictions
# Calcola l'accuratezza del modello
accuracy <- mean(predictions == test.df.4$Divorce)
print(paste("Accuracy:", accuracy))
# Calcola l'accuratezza del modello
accuracy <- mean(predictions == test.df$Divorce)
print(paste("Accuracy:", accuracy))
# Grafico di densità
plot(density(train.df.4))
# Grafico di densità
plot(density(train.df.4$Harmony_Understanding))
plot(density(train.df.4$Intimacy_Love))
plot(density(train.df.4$Similarity_Cohesion))
plot(density(train.df.4$Conflict_Level))
plot(density(train.df.4$Divorce))
# Grafico di densità
plot(density(train.df.4$Harmony_Understanding))
plot(density(train.df.4$Intimacy_Love))
plot(density(train.df.4$Similarity_Cohesion))
plot(density(train.df.4$Conflict_Level))
cor.test(train.df.4$Harmony_Understanding, train.df.4$Intimacy_Love)
# Test di Shapiro-Wilk per la normalità
shapiro.test(train.df.4$Harmony_Understanding)
model_linear <- lm(Divorce ∼ ., data=divorce_data)
model_linear <- lm(Divorce ~ ., data=divorce_data)
summary(model_linear)
model_linear <- lm(Divorce ~ ., data=train.df.4)
summary(model_linear)
model_linear <- lm(Divorce ~ ., data=train.df)
summary(model_linear)
rf_model <- randomForest(Divorce ~ ., data = train.df.4)
# Valuta le prestazioni del modello utilizzando il set di test
predictions <- predict(rf_model, newdata = test.df.4)
predictions
# Calcola l'accuratezza del modello
accuracy <- mean(predictions == test.df.4$Divorce)
print(paste("Accuracy:", accuracy))
View(test.df.4)
View(train.df.4)
# Valuta le prestazioni del modello utilizzando il set di test
predictions <- predict(rf_model, newdata = train.df.4)
predictions
# Calcola l'accuratezza del modello
accuracy <- mean(predictions == train.df.4$Divorce)
print(paste("Accuracy:", accuracy))
# Calcola l'errore medio assoluto (MAE)
mae <- mean(abs(predictions - test.df.4$Divorce))
cat("Mean Absolute Error (MAE):", mae, "\n")
# Calcola l'errore quadratico medio (MSE)
mse <- mean((predictions - test.df.4$Divorce)^2)
cat("Mean Squared Error (MSE):", Divorce, "\n")
cat("Mean Squared Error (MSE):", divorce_data$Divorce, "\n")
# Calcola l'errore quadratico medio (MSE)
mse <- mean((predictions - test.df.4$Divorce)^2)
cat("Mean Squared Error (MSE):", divorce_data$Divorce, "\n")
# Calcola l'errore quadratico medio (MSE)
mse <- mean((predictions - test.df.4$Divorce)^2)
cat("Mean Squared Error (MSE):", mse, "\n")
# Calcola l'errore medio assoluto (MAE)
mae <- mean(abs(predictions - train.df.4$Divorce))
cat("Mean Absolute Error (MAE):", mae, "\n")
# Effettua le previsioni
predictions_regr_lin <- predict(model_linear, newdata = test.df.4)
View(test.df.4)
View(train.df.4)
# Effettua le previsioni
predictions_regr_lin <- predict(model_linear, newdata = test.df.4)
# Calcola l'errore medio assoluto (MAE)
mae <- mean(abs(predictions - train.df.4$Divorce))
cat("Mean Absolute Error (MAE):", mae, "\n")
# Calcola l'errore medio assoluto (MAE)
mae <- mean(abs(predictions - test.df.4$Divorce))
cat("Mean Absolute Error (MAE):", mae, "\n")
rf_model <- randomForest(Divorce ~ ., data = train.df.4)
print(rf_model)
# Valuta le prestazioni del modello utilizzando il set di test
predictions_rf <- predict(rf_model, newdata = test.df.4)
accuracy <- mean(predictions_rf == test.df.4$Divorce)
accuracy
pred_rf_class <- ifelse(predictions_rf > 0.5, 1,0)
accuracy <- mean(pred_rf_class == test.df.4$Divorce)
accuracy
lda.fit <- lda(Divorce ~ ., data = train.df.4) # nota: no stand.
lda.fit
plot(lda.fit, col = "violet")
lda.pred <- predict(lda.fit, test.df.4)$class
table(lda.pred,test.df.4$Divorce)
mean(lda.pred==test.df.4$Divorce)
accuracy <- mean(pred_rf_class == test.df.4$Divorce)
accuracy
## Random forest sul dataset dei gruppi
rf_model <- randomForest(Divorce ~ ., data = train.df)
print(rf_model)
# Valuta le prestazioni del modello utilizzando il set di test
predictions_rf <- predict(rf_model, newdata = test.df)
pred_rf_class <- ifelse(predictions_rf > 0.5, 1,0)
accuracy <- mean(pred_rf_class == test.df$Divorce)
accuracy
## Random forest sul dataset totale
rf_model <- randomForest(Divorce ~ ., data = train.df.4)
print(rf_model)
# Valuta le prestazioni del modello utilizzando il set di test
predictions_rf <- predict(rf_model, newdata = test.df.4)
pred_rf_class <- ifelse(predictions_rf > 0.5, 1,0)
accuracy <- mean(pred_rf_class == test.df.4$Divorce)
accuracy
## Random forest sul dataset totale
rf_model_4 <- randomForest(Divorce ~ ., data = train.df.4)
print(rf_model_4)
# Valuta le prestazioni del modello utilizzando il set di test
predictions_rf <- predict(rf_model_4, newdata = test.df.4)
pred_rf_class <- ifelse(predictions_rf > 0.5, 1,0)
accuracy <- mean(pred_rf_class == test.df.4$Divorce)
accuracy
## Random forest sul dataset dei gruppi
rf_model <- randomForest(Divorce ~ ., data = train.df)
print(rf_model)
# Valuta le prestazioni del modello utilizzando il set di test
predictions_rf <- predict(rf_model, newdata = test.df)
pred_rf_class <- ifelse(predictions_rf > 0.5, 1,0)
accuracy <- mean(pred_rf_class == test.df$Divorce)
accuracy
## Random forest sul dataset totale
rf_model_4 <- randomForest(Divorce ~ ., data = train.df.4)
print(rf_model_4)
# Valuta le prestazioni del modello utilizzando il set di test
predictions_rf_4 <- predict(rf_model_4, newdata = test.df.4)
pred_rf_class_4 <- ifelse(predictions_rf > 0.5, 1,0)
accuracy_4 <- mean(pred_rf_class == test.df.4$Divorce)
accuracy_4
## Random forest sul dataset dei gruppi
rf_model <- randomForest(Divorce ~ ., data = train.df)
print(rf_model)
# Valuta le prestazioni del modello utilizzando il set di test
predictions_rf <- predict(rf_model, newdata = test.df)
pred_rf_class <- ifelse(predictions_rf > 0.5, 1,0)
accuracy <- mean(pred_rf_class == test.df$Divorce)
accuracy
## Random forest sul dataset totale
rf_model_4 <- randomForest(Divorce ~ ., data = train.df.4)
print(rf_model_4)
# Valuta le prestazioni del modello utilizzando il set di test
predictions_rf_4 <- predict(rf_model_4, newdata = test.df.4)
pred_rf_class_4 <- ifelse(predictions_rf_4 > 0.5, 1,0)
accuracy_4 <- mean(pred_rf_class_4 == test.df.4$Divorce)
accuracy_4
## Random forest sul dataset dei gruppi
rf_model <- randomForest(Divorce ~ ., data = train.df)
print(rf_model)
# Valuta le prestazioni del modello utilizzando il set di test
predictions_rf <- predict(rf_model, newdata = test.df)
pred_rf_class <- ifelse(predictions_rf > 0.5, 1,0)
accuracy <- mean(pred_rf_class == test.df$Divorce)
accuracy
View(test.df)
# Grafico di densità
plot(density(train.df.4$Harmony_Understanding))
plot(density(train.df.4$Intimacy_Love))
plot(density(train.df.4$Similarity_Cohesion))
plot(density(train.df.4$Conflict_Level))
# Grafico di densità
plot(density(train.df.4$Harmony_Understanding))
plot(density(train.df.4$Intimacy_Love))
plot(density(train.df.4$Similarity_Cohesion))
plot(density(train.df.4$Conflict_Level))
# Grafico Q-Q
qqnorm(data$variabile)
lda.fit <- lda(Divorce ~ ., data = train.df.4) # nota: no stand.
lda.fit
plot(lda.fit, col = "violet")
lda.pred <- predict(lda.fit, test.df.4)$class
table(lda.pred,test.df.4$Divorce)
mean(lda.pred==test.df.4$Divorce)
# Esempio con il dataset Iris
shapiro.test(test.df.4$Harmony_Understanding)
# Esempio con il dataset Iris
shapiro.test(test.df.4$Intimacy_Love)
# Esempio con il dataset Iris
shapiro.test(test.df.4$Similarity_Cohesion)
# Esempio con il dataset Iris
shapiro.test(test.df.4$Conflict_Level)
# Calcola la trasformazione logaritmica della variabile Harmony_Understanding
test.df.4$log_Harmony_Understanding <- log(test.df.4$Harmony_Understanding)
# Verifica se la trasformazione logaritmica ha reso i dati più normalmente distribuiti
shapiro.test(test.df.4$log_Harmony_Understanding)
library(MASS)
# Stimare il parametro lambda ottimale per la trasformazione Box-Cox
lambda <- boxcox(test.df.4$Harmony_Understanding)$x
lambda <- boxcox(test.df.4$Harmony_Understanding)$x
lambda <- boxcox(test.df.4$Harmony_Understanding)$x
lambda <- boxcox(y = test.df.4$Harmony_Understanding)$x
import matplotlib.pyplot as plt
library(randomForest)
library(caret)
# Visualizza l'importanza delle feature
feature_importances <- rf_model_4$importance
feature_names <- colnames(train.df.4[, -ncol(train.df.4)])
barplot(feature_importances, names.arg = feature_names, horiz = TRUE,
xlab = 'Importanza delle Feature', ylab = 'Feature',
main = 'Importanza delle Feature nel Random Forest')
View(feature_importances)
# Calcola l'importanza delle feature
feature_importances <- rf_model_4$importance
feature_names <- colnames(train.df.4[, -ncol(train.df.4)])
# Ordina le feature in base all'importanza
sorted_indices <- order(feature_importances, decreasing = TRUE)
sorted_importances <- feature_importances[sorted_indices]
sorted_names <- feature_names[sorted_indices]
# Crea il grafico a barre orizzontale
barplot(sorted_importances, horiz = TRUE,
main = 'Importanza delle Feature nel Random Forest',
xlab = 'Importanza delle Feature', ylab = 'Feature',
names.arg = sorted_names,
col = 'steelblue')
# Crea il grafico a barre orizzontale
barplot(sorted_importances, horiz = TRUE,
main = 'Importanza delle Feature nel Random Forest',
xlab = 'Importanza delle Feature', ylab = 'Feature',
names.arg = sorted_names,
col = 'steelblue',
las = 1)  # Imposta la direzione delle etichette a orizzontale
par(mar = c(5, 8, 4, 2) + 0.1)
# Crea il grafico a barre orizzontale
barplot(sorted_importances, horiz = TRUE,
main = 'Importanza delle Feature nel Random Forest',
xlab = 'Importanza delle Feature', ylab = 'Feature',
names.arg = sorted_names,
col = 'steelblue',
las = 1)  # Imposta la direzione delle etichette a orizzontale
# Crea il grafico a barre orizzontale
barplot(sorted_importances, horiz = TRUE,
main = 'Importanza delle Feature nel Random Forest',
xlab = 'Importanza delle Feature', ylab = '',
names.arg = sorted_names,
col = 'steelblue',
las = 1)  # Imposta la direzione delle etichette a orizzontale
par(mar = c(5, 7, 4, 2) + 0.1)
par(mar = c(5, 7, 3, 2) + 0.1)
barplot(sorted_importances, horiz = TRUE,
main = 'Importanza delle Feature nel Random Forest',
xlab = 'Importanza delle Feature', ylab = '',
names.arg = sorted_names,
col = 'steelblue',
las = 1)  # Imposta la direzione delle etichette a orizzontale
par(mar = c(5, 9, 5, 2) + 0.1)
barplot(sorted_importances, horiz = TRUE,
main = 'Importanza delle Feature nel Random Forest',
xlab = 'Importanza delle Feature', ylab = '',
names.arg = sorted_names,
col = 'steelblue',
las = 1)  # Imposta la direzione delle etichette a orizzontale
confusion_matrix <- table(test.df.4$Divorce, predictions_rf_4)
# Visualizza la matrice di confusione
confusion_matrix
heatmap(confusion_matrix,
col = heat.colors(length(confusion_matrix)),
scale = "none",
xlab = "Predicted Class",
ylab = "True Class",
main = "Matrice di Confusione")
barplot(sorted_importances, horiz = TRUE,
main = 'Importanza delle Feature nel Random Forest',
xlab = 'Importanza delle Feature', ylab = '',
names.arg = sorted_names,
col = 'steelblue',
las = 1)  # Imposta la direzione delle etichette a orizzontale
par(mar = c(5, 10, 5, 2) + 0.1)
barplot(sorted_importances, horiz = TRUE,
main = 'Importanza delle Feature nel Random Forest',
xlab = 'Importanza delle Feature', ylab = '',
names.arg = sorted_names,
col = 'steelblue',
las = 1)  # Imposta la direzione delle etichette a orizzontale
par(mar = c(5, 11, 5, 2) + 0.1)
barplot(sorted_importances, horiz = TRUE,
main = 'Importanza delle Feature nel Random Forest',
xlab = 'Importanza delle Feature', ylab = '',
names.arg = sorted_names,
col = 'steelblue',
las = 1)  # Imposta la direzione delle etichette a orizzontale
barplot(sorted_importances, horiz = TRUE,
main = 'Feature Importance in Random Forest',
xlab = 'Feature Importance', ylab = '',
names.arg = sorted_names,
col = 'steelblue',
las = 1)  # Imposta la direzione delle etichette a orizzontale
barplot(sorted_importances, horiz = TRUE,
main = 'Feature Importance in Random Forest',
xlab = 'Feature Importance', ylab = '',
names.arg = sorted_names,
col = '#227c9d',
las = 1)  # Imposta la direzione delle etichette a orizzontale
## Random forest sul dataset totale
rf_model_4 <- randomForest(Divorce ~ ., data = train.df.4)
print(rf_model_4)
# Converti la variabile 'Divorce' in una variabile categorica
train.df.4$Divorce <- as.factor(train.df.4$Divorce)
test.df.4$Divorce <- as.factor(test.df.4$Divorce)
# Addestra il modello Random Forest per la classificazione
rf_model_4 <- randomForest(Divorce ~ ., data = train.df.4)
# Valuta le prestazioni del modello utilizzando il set di test
predictions_rf_4 <- predict(rf_model_4, newdata = test.df.4)
# Calcola l'accuratezza del modello di classificazione
accuracy_4 <- mean(predictions_rf_4 == test.df.4$Divorce)
accuracy_4
print(rf_model_4)
# Converti la variabile 'Divorce' in una variabile categorica
train.df$Divorce <- as.factor(train.df$Divorce)
test.df$Divorce <- as.factor(test.df$Divorce)
# Addestra il modello Random Forest per la classificazione
rf_model <- randomForest(Divorce ~ ., data = train.df)
print(rf_model)
# Valuta le prestazioni del modello utilizzando il set di test
predictions_rf <- predict(rf_model, newdata = test.df)
# Calcola l'accuratezza del modello di classificazione
accuracy <- mean(predictions_rf == test.df$Divorce)
accuracy
train.df.4$Divorce <- as.factor(train.df.4$Divorce)
test.df.4$Divorce <- as.factor(test.df.4$Divorce)
rf_model_4 <- randomForest(Divorce ~ ., data = train.df.4)
print(rf_model_4)
# Valuta le prestazioni del modello utilizzando il set di test
predictions_rf_4 <- predict(rf_model_4, newdata = test.df.4)
pred_rf_class_4 <- ifelse(predictions_rf_4 > 0.5, 1,0)
accuracy_4 <- mean(pred_rf_class_4 == test.df.4$Divorce)
accuracy_4
# Valuta le prestazioni del modello utilizzando il set di test
predictions_rf_4 <- predict(rf_model_4, newdata = test.df.4)
# Calcola l'accuratezza del modello di classificazione
accuracy_4 <- mean(predictions_rf_4 == test.df.4$Divorce)
accuracy_4
## Random forest sul dataset dei gruppi
train.df$Divorce <- as.factor(train.df$Divorce)
test.df$Divorce <- as.factor(test.df$Divorce)
rf_model <- randomForest(Divorce ~ ., data = train.df)
print(rf_model)
# Valuta le prestazioni del modello utilizzando il set di test
predictions_rf <- predict(rf_model, newdata = test.df)
accuracy <- mean(pred_rf_class == test.df$Divorce)
accuracy
feature_importances_4 <- rf_model_4$importance
feature_names_4 <- colnames(train.df.4[, -ncol(train.df.4)])
sorted_indices_4 <- order(feature_importances, decreasing = TRUE)
sorted_importances_4 <- feature_importances[sorted_indices]
sorted_names_4 <- feature_names[sorted_indices]
par(mar = c(5, 11, 5, 2) + 0.1)
barplot(sorted_importances, horiz = TRUE,
main = 'Feature Importance in Random Forest',
xlab = 'Feature Importance', ylab = '',
names.arg = sorted_names,
col = '#227c9d',
las = 1)
feature_importances <- rf_model$importance
feature_names <- colnames(train.df[, -ncol(train.df)])
sorted_indices <- order(feature_importances, decreasing = TRUE)
sorted_importances <- feature_importances[sorted_indices]
sorted_names <- feature_names[sorted_indices]
par(mar = c(5, 11, 5, 2) + 0.1)
barplot(sorted_importances, horiz = TRUE,
main = 'Feature Importance in Random Forest',
xlab = 'Feature Importance', ylab = '',
names.arg = sorted_names,
col = '#227c9d',
las = 1)
